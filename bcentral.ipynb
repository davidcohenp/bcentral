{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "class BancoCentralChile:\n",
    "    \"\"\"\n",
    "    Requests the Central Bank of Chile for data from a selected time period.\n",
    "    Object gets a .df attribute with the returned time series as a pandas DataFrame() object.\n",
    "    \n",
    "    Params:\n",
    "        - series_begin: year in which data begins. Starts from January 1st.\n",
    "        - series_end: year in which data ends. Ends on December 31st.\n",
    "        - param: Needs to be extracted from bcentral.cl's dynamic Excel query (.iqy)\n",
    "            http://si3.bcentral.cl/Siete/secure/cuadros/home.aspx\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, series_begin, series_end, param):\n",
    "        url = 'http://si3.bcentral.cl/SieteIQY/secure/carga_series_excel.aspx' # as of 2016.11.01\n",
    "        self.fechaInicio = series_begin\n",
    "        self.fechaFin = series_end\n",
    "        self.param = param\n",
    "        self.payload = {'fechaInicio': str(self.fechaInicio),\n",
    "                        'fechaFin': str(self.fechaFin),\n",
    "                        'param': self.param\n",
    "                       }\n",
    "        \n",
    "        def get_soup(payload):\n",
    "            r = requests.post(url, data=payload)\n",
    "            try:\n",
    "                soup = BeautifulSoup(r.text, 'lxml') #faster\n",
    "            except:\n",
    "                soup = BeautifulSoup(r.text, 'html.parser') #default\n",
    "            return soup\n",
    "        \n",
    "        def get_headers(tables):\n",
    "            headers = tables[0]\n",
    "            headers = headers.tr\n",
    "            clean_headers = []\n",
    "            for i in headers:\n",
    "                try:\n",
    "                    clean_headers.append(i.text)\n",
    "                except AttributeError:\n",
    "                    # data might contain useless info which raises exception, skip\n",
    "                    pass\n",
    "            return clean_headers\n",
    "            \n",
    "        def get_data_columns(tables):\n",
    "            final_data = []\n",
    "            for tseries in tables[1:]:\n",
    "                series = []\n",
    "                for item in tseries:\n",
    "                    series.extend(item.td.contents)\n",
    "                final_data.append(series)\n",
    "            return final_data\n",
    "        \n",
    "        def replace_string(data_list, replace_string='--', replacement=None):\n",
    "            replaced_data = []\n",
    "            for series in data_list:\n",
    "                replaced = [replacement if x == replace_string else x for x in series]\n",
    "                replaced_data.append(replaced)\n",
    "            return replaced_data\n",
    "        \n",
    "        def data_to_float(data):\n",
    "            return_data = [data[0]]\n",
    "            for data_series in data[1:]: #skip dates\n",
    "                temp_data = [float(i) if i is not None else i for i in data_series]\n",
    "                return_data.append(temp_data)\n",
    "            return return_data\n",
    "\n",
    "        def check_data_length(data):\n",
    "            # http://stackoverflow.com/questions/16720844/compare-length-of-three-lists-in-python\n",
    "            length = len(data[0])\n",
    "            if all(len(lst) == length for lst in data[1:]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        def get_zipped_data(data):\n",
    "            return [i for i in zip(*data)]\n",
    "        \n",
    "        def get_dataframe(data=None, index=None, columns=None):\n",
    "            return pd.DataFrame(data=data, index=index, columns=columns)\n",
    "\n",
    "        soup = get_soup(self.payload)\n",
    "        tables = soup.find_all('table')\n",
    "        headers = get_headers(tables)\n",
    "        data = get_data_columns(tables)\n",
    "        data = replace_string(data, replace_string='--', replacement=None)\n",
    "        data = data_to_float(data)\n",
    "        if not check_data_length(data):\n",
    "            raise AssertionError(\"Length of data series doesn't match\")\n",
    "        final_data = get_zipped_data(data)\n",
    "        self.df = get_dataframe(final_data, columns=headers)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
